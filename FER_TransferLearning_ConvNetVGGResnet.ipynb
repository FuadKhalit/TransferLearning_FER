{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER_TransferLearning_ConvNetVGGResnet.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qEM21ssWrzms",
        "azZweA-2hLct",
        "tmRmVniGhWst",
        "SjTMscFUb6P2",
        "H5A77zi5Vng9"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FuadKhalit/TransferLearning_FER/blob/main/FER_TransferLearning_ConvNetVGGResnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV2SEhLnSDMm"
      },
      "source": [
        "\r\n",
        "<center>Ahmad Fuad Bin Khalit</center>\r\n",
        "<center>TP058497</center>\r\n",
        "<center>CT-100-3-M-DL</center>\r\n",
        "<center>Asia Pacific University Malaysia</center>\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8_kfzRZND68"
      },
      "source": [
        "<h1>Model Implementation</h1>\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdFTYVCGUGRu"
      },
      "source": [
        "For Model implementation, the experiment will compared 3 model to find the best architecture to use for e-KYC system. The best model will be choose based on the latency, inference and accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laTsUKueFE2i"
      },
      "source": [
        "#install plugin for tensorboard\r\n",
        "!pip install -U tensorboard_plugin_profile # to install profile plugin in tensorboard\r\n",
        "!pip install memory_profiler #to monitor memory usage of each line\r\n",
        "!pip install line_profiler #to monitor time use"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJAIJzllIFt5"
      },
      "source": [
        "Mounting the Drive to colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h93J995_dAf4"
      },
      "source": [
        "#Mounting google drive to colab\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1llK-ODP-6x"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZGH9x8xIKeS"
      },
      "source": [
        "Importing all required Library to environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sIRvKOhNlGb"
      },
      "source": [
        "#Load Line Profiler extension\r\n",
        "%load_ext line_profiler\r\n",
        "\r\n",
        "#Load Memory Profiler extension\r\n",
        "%load_ext memory_profiler\r\n",
        "\r\n",
        "# Load the TensorBoard notebook extension\r\n",
        "%load_ext tensorboard\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoeyd_z3dVa-"
      },
      "source": [
        "%time\n",
        "#Import Python Library\n",
        "import itertools\n",
        "import datetime, os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "#Import Tensorflow Keras Library\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import keras.callbacks\n",
        "from keras.callbacks import TensorBoard\n",
        "from tensorflow import keras\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import Sequential\n",
        "from keras import regularizers\n",
        "from keras.layers import AveragePooling2D\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from keras.applications import VGG16, VGG19, ResNet50\n",
        "from keras.layers import Flatten, Dropout, Reshape, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.models import model_from_json\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "from keras.utils import  plot_model\n",
        "from keras.applications.resnet50 import preprocess_input\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujUZaLveS3ow"
      },
      "source": [
        "* The Dataset link [Kaggle Competition: Emotion and Identity detection from face image](https://www.kaggle.com/c/facial-keypoints-detector)\r\n",
        "* 2nd Dataset link [Challenges in Representation Learning: Facial Expression Recognition Challenge](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7tvfyhNdpQC"
      },
      "source": [
        "%time\n",
        "# Read in the files from Google Drive\n",
        "\n",
        "#train_df = pd.read_csv('/content/drive/MyDrive/Fuad_Assignment/train.csv')# 4178 dataset | 1st google drive acc\n",
        "#train_df = pd.read_csv('/content/drive/MyDrive/Deep Learning/Assignment2/FER2013.csv')# 28709 dataset | 1st google drive acc\n",
        "#train_df = pd.read_csv('/content/drive/MyDrive/Deep Learning/Assignment2/train.csv') # 4178 dataset | second google drive acc\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/Deep Learning/Assignment2/FER2013.csv')# 28709 dataset | second google drive acc\n",
        "\n",
        "train_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqGie3KDhSX3"
      },
      "source": [
        "Metadata Explaination\n",
        "\n",
        "*   Source: https://www.kaggle.com/c/facial-keypoints-detector\n",
        "*   Data are in csv file with 4178 image\n",
        "*   input: 48x48 pixel grayscale (between 0 and 255)\n",
        "*   target output:between 0 and 6: anger=0, disgust=1, fear=2, happy=3, sad=4, surprise=5, neutral=6)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEM21ssWrzms"
      },
      "source": [
        "# **Data Exploration**\r\n",
        "\r\n",
        "use numpy to rebuild the csv value to image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4Z8JYVEoZkk"
      },
      "source": [
        "#check for imbalance of data\r\n",
        "sns.countplot(x='emotion', data=train_df, palette='RdBu_r')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nk6Ywndj8Pe"
      },
      "source": [
        "%%time\n",
        "# View an image #1\n",
        "i = 2500\n",
        "list_pixels = np.array([int(string) for string in train_df.iloc[i,1].split(' ')])\n",
        "pixeled_image = list_pixels.reshape(48,48)\n",
        "plt.imshow(pixeled_image, cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zcf1YeU-tXCD"
      },
      "source": [
        "# View an image #2\n",
        "i = 1500\n",
        "list_pixels = np.array([int(string) for string in train_df.iloc[i,1].split(' ')])\n",
        "pixeled_image = list_pixels.reshape(48,48)\n",
        "%timeit plt.imshow(pixeled_image, cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuuTLz9aD06i"
      },
      "source": [
        "# **Preprocess data for base model: Convolution Layer CNN 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5gSHM5h3h52"
      },
      "source": [
        "#%%timeit\n",
        "%%memit\n",
        "# Reshape 1D array to 2D matrix for Conv2D\n",
        "\n",
        "x_train = []\n",
        "for i in range(len(train_df)):\n",
        "  # convert string of pixels to list of integers\n",
        "  list_pixels = [int(string) for string in train_df.iloc[i,1].split(' ')]\n",
        "  # reshape 1D to 2D matrix\n",
        "  pixeled_image = np.array(list_pixels).reshape(48,48)\n",
        "  x_train.append(pixeled_image)\n",
        "\n",
        "x = np.array(x_train)\n",
        "y = train_df.iloc[:,0]\n",
        "print (y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae4Jl1ENDTwY"
      },
      "source": [
        "# Categorize y for compatiblity with softmax activation\n",
        "from keras.utils import to_categorical\n",
        "y = to_categorical(np.array(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_s0_cV_DZMd"
      },
      "source": [
        "print(x.shape) # (4178, 48, 48)\n",
        "y.shape # (4178, 7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWbxt1MDb96"
      },
      "source": [
        "# Train_test_split training data into training and test sets\n",
        "x_train1, x_test, y_train1, y_test =  train_test_split(x, y, random_state = 123, test_size = 0.10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yehHni0aDcxd"
      },
      "source": [
        "# Train_test_split training data into training and validation sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train1, y_train1, random_state = 123, test_size = 0.40)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train1, y_train1, random_state = 123, test_size = 0.40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYHQR1MzDemQ"
      },
      "source": [
        "# Check shapes to ensure it's right\n",
        "print(x_train.shape) # (3008, 48, 48)\n",
        "print(x_test.shape) # (418, 48, 48)\n",
        "print(y_train.shape) # (3008, 7)\n",
        "print(y_test.shape) # (418, 7)\n",
        "print(x_val.shape) # (752, 48,48)\n",
        "print(y_val.shape) #(752, 7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1gS2l47Djsf"
      },
      "source": [
        "# Reshape the data to be  (2924, 48, 48, 1) and (1254, 48, 48, 1) for x_train and x_val\n",
        "# respectively. need to do this because input_shape in model_cnn.add needs a 2D image with \n",
        "# depth specified as 1\n",
        "x_train_reshaped = np.expand_dims(x_train, axis = 3)\n",
        "x_val_reshaped = np.expand_dims(x_val, axis = 3)\n",
        "x_test_reshaped = np.expand_dims(x_test, axis = 3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDEuiF2bDmSp"
      },
      "source": [
        "print(x_train_reshaped.shape) #(3008, 48, 48, 1)\n",
        "print(x_val_reshaped.shape) #(752, 48, 48, 1)\n",
        "print(x_test_reshaped.shape) #(418, 48, 48, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG82yN4FEEG4"
      },
      "source": [
        "# **Train Base Layer : CNN 1**\r\n",
        "\r\n",
        "---\r\n",
        "This is the experiment basic architecture & using manual search for hyperparameter\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DngkLicrEL5w"
      },
      "source": [
        "# Setting Hyperparameter (For Manual Search of Hyperparameter)\n",
        "unit1 = 2048\n",
        "unit2 = 128\n",
        "\n",
        "\n",
        "# Define model as Sequential class\n",
        "\n",
        "model_cnn = models.Sequential()\n",
        "\n",
        "#Feature Extraction Layer\n",
        "model_cnn.add(Conv2D(1, kernel_size=(3, 3), strides=(1, 1),\n",
        "                 activation='relu',\n",
        "                   input_shape=(48,48,1)))\n",
        "model_cnn.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model_cnn.add(BatchNormalization(trainable=True))\n",
        "model_cnn.add(layers.Dropout(0.3))#layer for larger dataset\n",
        "model_cnn.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_cnn.add(layers.Dropout(0.3))#layer for larger dataset\n",
        "model_cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_cnn.add(layers.Dropout(0.3))#layer for larger dataset\n",
        "model_cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model_cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_cnn.add(layers.Dropout(0.3))#layer for larger dataset\n",
        "#Fully Connected Layer\n",
        "model_cnn.add(layers.Flatten())\n",
        "model_cnn.add(layers.Dense(unit1, activation='relu'))\n",
        "model_cnn.add(layers.Dropout(0.3))#layer for larger dataset\n",
        "model_cnn.add(layers.Dense(unit2, activation='relu'))\n",
        "model_cnn.add(layers.Dense(7, activation='softmax')) # 7 classifications\n",
        "model_cnn.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep0S46T_2a7q"
      },
      "source": [
        "#to stop overfitting\r\n",
        "earlystop = EarlyStopping(monitor='val_loss',\r\n",
        "                              min_delta=0.01, #minimum change for improvement\r\n",
        "                              patience=30, # trigger when there is no improvement\r\n",
        "                              verbose=0, mode='auto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdFJ-83zEQSe"
      },
      "source": [
        "model_cnn.compile(loss='categorical_crossentropy',\n",
        "              optimizer=\"sgd\",\n",
        "              metrics=['acc'])\n",
        "\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logdir/CNN7/\", histogram_freq=1, profile_batch='15,20')\n",
        "\n",
        "history_cnn = model_cnn.fit(x_train_reshaped,\n",
        "                        y_train,\n",
        "                        epochs = 500,                  \n",
        "                        batch_size=100,\n",
        "                        validation_data=(x_val_reshaped, y_val),\n",
        "                        callbacks=[tensorboard_callback,earlystop]\n",
        "                       )\n",
        "\n",
        "#print(\"Average test loss: \", np.average(history_cnn.history['loss'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59QZj2k_Nqaf"
      },
      "source": [
        "#validation\r\n",
        "#evaluate the model using test set\r\n",
        "model_cnn.evaluate(x_test_reshaped,y_test)\r\n",
        "model_cnn\r\n",
        "#90/90 [==============================] - 0s 3ms/step - loss: 1.4656 - acc: 0.4375"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K6TftBKxVjJ"
      },
      "source": [
        "#Start TensorBoard within the notebook using magics\n",
        "%tensorboard --logdir /content/logdir/CNN7/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z11hJBlWUS7"
      },
      "source": [
        "Tensorboard Result:\r\n",
        "The model run faster but the accuracy is too low "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6-K4n-rWKuN"
      },
      "source": [
        "# **Transfer Learning VGG Model**\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D_l7SZ9XPsX"
      },
      "source": [
        "**Data Preprocessing**\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Data processing for the VGG model is different from our based model due to transfer learning takes RGB format for VGG model. The process are as below:\r\n",
        "\r\n",
        "1.   Reshape train data(x) from 1D array to 2D matrix (using numpy array) & create label(y) from train data\r\n",
        "2.   Convert numpy array to matrix for label (y)\r\n",
        "3.   Split train data into train set & test set and their label (y)\r\n",
        "4.   From train set, split it into train & validation set & their label (y)\r\n",
        "5.   Reshaped all train, valid & test (x) by inserting new axis \r\n",
        "6.   Then use repeat function to flatten output\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSEm0yhEQvR6"
      },
      "source": [
        "#Clear Previous memory allocation\r\n",
        "%reset -f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56SPONGaWTSV"
      },
      "source": [
        "# Reshape 1D array to 2D matrix for Conv2D\n",
        "\n",
        "x_train = []\n",
        "for i in range(len(train_df)):\n",
        "  # convert string of pixels to list of integers and standarize data\n",
        "  list_pixels = [int(string)/255 for string in train_df.iloc[i,1].split(' ')]\n",
        "  # reshape 1D to 2D matrix\n",
        "  pixeled_image = np.array(list_pixels).reshape(48,48)\n",
        "  x_train.append(pixeled_image)\n",
        "\n",
        "x = np.array(x_train)\n",
        "y = train_df.iloc[:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NawRD_SXJgM"
      },
      "source": [
        "# Categorize y to y category for compatiblity with softmax activation\n",
        "from keras.utils import to_categorical\n",
        "y = to_categorical(np.array(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azpE3xJiXUIB"
      },
      "source": [
        "print(x.shape) # (4178, 48, 48)\n",
        "y.shape # (4178, 7)\n",
        "(4178, 48, 48)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2xhWbPaXXQr"
      },
      "source": [
        "# Train_test_split training data into training and test sets\n",
        "x_train1, x_test, y_train1, y_test =  train_test_split(x, y, \\\n",
        "                                          random_state = 123, test_size = 0.10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IL-UhOsXauD"
      },
      "source": [
        "# Create train_test_split for validation sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train1, y_train1, random_state = 123, test_size = 0.40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2BG0MwtXeWJ"
      },
      "source": [
        "# Check shapes to ensure it's right\n",
        "print(x_train.shape) # (3008, 48, 48)\n",
        "print(x_test.shape) # (418, 48, 48)\n",
        "print(y_train.shape) # (3008, 7)\n",
        "print(y_test.shape) # (418, 7)\n",
        "print(x_val.shape) # (752, 7)\n",
        "print(y_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-4dDs2CXhtM"
      },
      "source": [
        "# Reshape the data to be  (2924, 48, 48, 1) and (1254, 48, 48, 1) for x_train and x_val\n",
        "# respectively. need to do this because input_shape in model_cnn.add needs a 2D image with \n",
        "# depth specified as 1\n",
        "x_train_reshaped = np.expand_dims(x_train, axis = 3)\n",
        "x_val_reshaped = np.expand_dims(x_val, axis = 3)\n",
        "x_test_reshaped = np.expand_dims(x_test, axis = 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbY9ibwIXk7n"
      },
      "source": [
        "# Need to repeat our 48x48x1 to 3 dimensions, because transfer learning models take RGB format\n",
        "#For VGG Model\n",
        "x_train_rgb = np.repeat(x_train_reshaped, 3, axis=3)\n",
        "x_val_rgb = np.repeat(x_val_reshaped, 3, axis=3)\n",
        "x_test_rgb = np.repeat(x_test_reshaped, 3, axis=3)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfG5XdzhXnsv"
      },
      "source": [
        "print(x_train_rgb.shape) #(3008, 48, 48, 3)\n",
        "print(x_val_rgb.shape) #(752, 48, 48, 3)\n",
        "print(x_test_rgb.shape) #(418, 48, 48, 3)\n",
        "print(x_train_rgb.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gYM4YsKXt7l"
      },
      "source": [
        "**Build & Run The Pre-trained Model**\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Using keras pretrain VGG16 architecture. The model will be cut the top layer which contain its fully connected layer (FC) from its original model and will be replace with facial emotion detection FC. NO modification was made on this architecture as we'll use hyperparameter search & data input pipeline to optimized from this basic pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luJmzBlrXxkG"
      },
      "source": [
        "#Experimenting with tuning the Pretrained Layer\n",
        "\n",
        "vgg_base = VGG16(include_top= False, weights='imagenet', input_shape = (48,48,3))\n",
        "\n",
        "#set freeze & unfreeze layer\n",
        "#vgg_base.trainable = False #freeze all so gradient descend wont modify them\n",
        "vgg_base.trainable = True #unfreeze specified layer to let backprop tweak them to increase performance (Rule: >train data >layer can unfreeze )\n",
        "\n",
        "print(\"Number of layers in the base model: \", len(vgg_base.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards (make sure to unfreeze layer first before finetune)\n",
        "fine_tune_at = 17 # backprop will tweak layer 17 to 19\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in vgg_base.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False\n",
        "vgg_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2x8RKbKX-vh"
      },
      "source": [
        "# # Define model as Sequential class (Small Dataset)\n",
        "# model_vgg = models.Sequential()\n",
        "# model_vgg.add(vgg_base)\n",
        "# model_vgg.add(layers.GlobalAveragePooling2D())\n",
        "# model_vgg.add(layers.Dense(128, activation='relu'))\n",
        "# model_vgg.add(BatchNormalization(momentum=0.5))\n",
        "# model_vgg.add(layers.Dropout(0.3))\n",
        "# model_vgg.add(layers.Dense(7, activation='softmax')) # 7 classifications\n",
        "# model_vgg.summary()    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7dm1zSQrvqV"
      },
      "source": [
        "# Define model as Sequential class (Large Dataset)\r\n",
        "model_vgg = models.Sequential()\r\n",
        "model_vgg.add(vgg_base)\r\n",
        "model_vgg.add(BatchNormalization(momentum=0.5, trainable=True))\r\n",
        "model_vgg.add(layers.GlobalAveragePooling2D())\r\n",
        "model_vgg.add(layers.Dense(1028, activation='tanh'))\r\n",
        "model_vgg.add(BatchNormalization(momentum=0.5, trainable=True))\r\n",
        "model_vgg.add(layers.Dropout (0.4))\r\n",
        "model_vgg.add(layers.Dense(128, activation='tanh'))\r\n",
        "model_vgg.add(BatchNormalization(momentum=0.5, trainable=True))\r\n",
        "model_vgg.add(layers.Dropout (0.4))\r\n",
        "model_vgg.add(layers.Dense(16, activation='tanh'))\r\n",
        "model_vgg.add(BatchNormalization(momentum=0.5, trainable=True))\r\n",
        "model_vgg.add(layers.Dropout (0.4))\r\n",
        "model_vgg.add(layers.Dense(7, activation='softmax')) # 7 classifications\r\n",
        "model_vgg.summary()    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05RLqxemYAHk"
      },
      "source": [
        "model_vgg.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=\"adam\",\n",
        "                  metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijQfR5enalzj"
      },
      "source": [
        "#to stop overfitting\r\n",
        "earlystop = EarlyStopping(monitor='val_loss',\r\n",
        "                              min_delta=0.01, #minimum change for improvement\r\n",
        "                              patience=10, # trigger when there is no improvement\r\n",
        "                              verbose=0, mode='auto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL7Ys4kwYVEK"
      },
      "source": [
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logdir/vgg1.9/\", histogram_freq=1, profile_batch='15,20')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfpOk97EYXlh"
      },
      "source": [
        "history_vgg = model_vgg.fit(x_train_rgb,\n",
        "                    y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=100,\n",
        "                    validation_data=(x_val_rgb, y_val), \n",
        "                    callbacks = [tensorboard_callback, earlystop])\n",
        "\n",
        "#Experiment 1 (Freeze all layer)\n",
        "#Epoch 15/15\n",
        "#301/301 [==============================] - 5s 16ms/step - loss: 0.9009 - acc: 0.6729 - val_loss: 1.0564 - val_acc: 0.6064\n",
        "#experiment 2 (unfreeze layer 16-19)\n",
        "#Epoch 15/15\n",
        "#301/301 [==============================] - 7s 22ms/step - loss: 0.2477 - acc: 0.9132 - val_loss: 0.6415 - val_acc: 0.7766\n",
        "#experiment 3 (unfreeze layer 3-19)\n",
        "#Epoch 15/15\n",
        "#301/301 [==============================] - 12s 40ms/step - loss: 0.0851 - acc: 0.9727 - val_loss: 0.4739 - val_acc: 0.8750\n",
        "#Summary of experiment\n",
        "# the more layer we unfreeze the higher the accuracy but in expense of speed of the training\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_sx6YEWZY14"
      },
      "source": [
        "#evaluate the model using test set\r\n",
        "model_vgg.evaluate(x_test_rgb,y_test)\r\n",
        "model_vgg\r\n",
        "\r\n",
        "#freeze all Layer\r\n",
        "#14/14 [==============================] - 0s 13ms/step - loss: 0.9762 - acc: 0.7010\r\n",
        "#unfreeze at 16th layer\r\n",
        "#14/14 [==============================] - 0s 13ms/step - loss: 0.7975 - acc: 0.8182\r\n",
        "#unfreeze 3rd layer\r\n",
        "#14/14 [==============================] - 0s 12ms/step - loss: 0.5753 - acc: 0.8995"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZkoSfZa1oRF"
      },
      "source": [
        "%tensorboard --logdir /content/logdir/vgg1.9/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZe72u2BC9CT"
      },
      "source": [
        "Tensorboard Analysis:\r\n",
        "\r\n",
        "---\r\n",
        "training set loss function was low but the validation set is high. This show that there are overfitting problem in the model.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZvMtDR7dr82"
      },
      "source": [
        "14/14 [==============================] - 0s 7ms/step - loss: 1.2188 - acc: 0.5478"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ougg3Ynt_qHN"
      },
      "source": [
        "# **Input PipeLine Experiment (VGG16)**\r\n",
        "This will maximize throughput of training session\r\n",
        "Input Pipeline = ETL Process : \r\n",
        "\r\n",
        "1.   Extract (extract the data from in memory to data pipeline)\r\n",
        "2.   Transform (normalize, transform the data)\r\n",
        "3.   Load (load to training model)\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noJU7CHefSDO"
      },
      "source": [
        "#change the dataset type from float64 to float32 (for performance advantage as tensorflow GPU are design for 32bit number)\r\n",
        "x_train_rgb =tf.cast(x_train_rgb, tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCJWVExG_5s0"
      },
      "source": [
        "#extract dataset into Tensorflow tf.data (API for input pipeline)\r\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train_rgb, y_train)).batch(512)\r\n",
        "valid_ds =tf.data.Dataset.from_tensor_slices((x_val_rgb, y_val)).batch(512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U2wJF99YnFH"
      },
      "source": [
        "# START THE TRANSFORMING PROCESS\r\n",
        "#function to normalize image \r\n",
        "def normalize_img (image, label):\r\n",
        "  return tf.cast(image, tf.float32)/255.0, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIVpAvE3Hgzm"
      },
      "source": [
        "#Automatic the tuning parameter in data pipeline\r\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouZ3fuMBAIWC"
      },
      "source": [
        "train_auto = train_ds.map(normalize_img,num_parallel_calls=AUTOTUNE)# Normalization the data function using map function \r\n",
        "train_auto = train_ds.cache() #caches the dataset after normalizing the images\r\n",
        "train_auto = train_ds.shuffle(buffer_size= 100) # to create randomness in dataset so to avoid bias when training the model\r\n",
        "train_auto = train_ds.batch(batch_size=64)# number of image batch into data pipeline\r\n",
        "train_auto = train_ds.prefetch(buffer_size = AUTOTUNE) #to alter the preprocessing execution\r\n",
        "valid_auto = valid_ds.map(normalize_img,num_parallel_calls=AUTOTUNE)\r\n",
        "valid_auto = valid_ds.batch(batch_size=64)\r\n",
        "valid_auto = valid_ds.prefetch(buffer_size= AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3LcxnVjH1fu"
      },
      "source": [
        "# Instantiate a base model with pre-trained weights\r\n",
        "vgg_base = VGG16(include_top= False, weights='imagenet', input_shape = (48,48,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy06tXBbHz_I"
      },
      "source": [
        "# Define model as Sequential class using default transfer learning setting\r\n",
        "model_vggip = models.Sequential()\r\n",
        "model_vggip.add(vgg_base) # load the pre-trained base model (Load Process)\r\n",
        "model_vggip.add(layers.Flatten())\r\n",
        "model_vggip.add(layers.Dense(128, activation='tanh'))\r\n",
        "model_vggip.add(layers.Dense(64, activation='tanh'))\r\n",
        "model_vggip.add(layers.Dense(7, activation='softmax')) # 7 classifications\r\n",
        "model_vggip.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhSEVBjoIbOa"
      },
      "source": [
        "#Configures the model for training\r\n",
        "model_vggip.compile(loss='categorical_crossentropy',\r\n",
        "                  optimizer=\"sgd\",\r\n",
        "                  metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWGQ7Hs6IgcS"
      },
      "source": [
        "#Setting up Tensorboard callback parameter\r\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logdir/vgg_IP/\", histogram_freq=1, profile_batch='15,20')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn-VdeAZImq6"
      },
      "source": [
        "#Trains the model for a fixed number of epochs (iterations on a dataset).\r\n",
        "history_cnn = model_vggip.fit(train_auto,\r\n",
        "                    epochs=15,\r\n",
        "                    validation_data=valid_auto, \r\n",
        "                    callbacks = [tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TgxPAGcItXu"
      },
      "source": [
        "#run the tensorboard to monitor data input pipeline profile (to see any improvement on step time speed, GPU optimizing)\r\n",
        "%tensorboard --logdir /content/logdir/vgg_IP/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0cAc1lfVBPX"
      },
      "source": [
        "# **HyperParameter GridSearch VGG16**\r\n",
        "\r\n",
        "---\r\n",
        "Identify the best hyperparameters for the model\r\n",
        "Inspired by https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams & https://medium.com/ml-book/neural-networks-hyperparameter-tuning-in-tensorflow-2-0-a7b4e2b574a1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gr8Qx3xIjsj"
      },
      "source": [
        "#Hyperparameter 1st Run\r\n",
        "HP_FREEZE = hp.HParam('fine_tune_at', hp.Discrete([5, 9, 16])) \r\n",
        "HP_NUM_UNITS = hp.HParam('num_units2', hp.Discrete([256,512]))\r\n",
        "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1,0.3))\r\n",
        "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\r\n",
        "\r\n",
        "METRIC_ACCURACY = 'accuracy'\r\n",
        "\r\n",
        "with tf.summary.create_file_writer('logs/hparam_vgg').as_default():\r\n",
        "  hp.hparams_config(\r\n",
        "    hparams=[HP_FREEZE,HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\r\n",
        "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\r\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FYEHrraU_uc"
      },
      "source": [
        "# # Experiment setup by choosing hyperparameter for tuning\r\n",
        "# HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16, 32]))\r\n",
        "# HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\r\n",
        "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\r\n",
        "\r\n",
        "# METRIC_ACCURACY = 'accuracy'\r\n",
        "\r\n",
        "# #Log experiment configuration to tensorboard\r\n",
        "# with tf.summary.create_file_writer('logs/hparam_tuningvgg16').as_default():\r\n",
        "#   hp.hparams_config(\r\n",
        "#     hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\r\n",
        "#     metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\r\n",
        "#   )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvUY5-MoJbHW"
      },
      "source": [
        "def train_test_resnetmodel(hparams):\r\n",
        "    resnet_base = VGG16(include_top= False, weights='imagenet', input_shape = (48,48,3))\r\n",
        "    resnet_base.trainable = True #False = Freeze all | True = Train Selected Layer\r\n",
        "\r\n",
        "    #Fine-tune from this layer onwards (make sure to unfreeze layer first before finetune)\r\n",
        "    fine_tune_at = hparams[HP_FREEZE] # backprop will tweak layer 20 to 175\r\n",
        "\r\n",
        "# Freeze all the layers before the `fine_tune_at` layer\r\n",
        "    for layer in resnet_base.layers[:fine_tune_at]:\r\n",
        "\r\n",
        "        layer.trainable =  False\r\n",
        "\r\n",
        "#Adapt TensorFlow run & log it into tensorboard \r\n",
        "def train_test_model(hparams):\r\n",
        "  vgghp_model = tf.keras.models.Sequential([tf.keras.applications.VGG16(include_top= False, weights='imagenet', input_shape = (48,48,3)),\r\n",
        "                                      tf.keras.layers.Flatten(),\r\n",
        "                                      tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation='tanh'),\r\n",
        "                                      tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\r\n",
        "                                      tf.keras.layers.Dense(7, activation=tf.nn.softmax), # 7 classifications\r\n",
        "                                    ])\r\n",
        "          \r\n",
        "  vgghp_model.compile(optimizer=hparams[HP_OPTIMIZER],\r\n",
        "                loss='categorical_crossentropy',\r\n",
        "                metrics=['accuracy'],\r\n",
        "  )\r\n",
        "  \r\n",
        "  history = vgghp_model.fit(train_auto,epochs=15)\r\n",
        "  validation_data=(valid_auto),  \r\n",
        " \r\n",
        "  return history.history['accuracy'][-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5FjGWMaV-b1"
      },
      "source": [
        "# #Adapt TensorFlow run & log it into tensorboard \r\n",
        "# def train_test_model(hparams):\r\n",
        "#   vgghp_model = tf.keras.models.Sequential([tf.keras.applications.VGG16(include_top= False, weights='imagenet', input_shape = (48,48,3)),\r\n",
        "#                                       tf.keras.layers.Flatten(),\r\n",
        "#                                       tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation='tanh'),\r\n",
        "#                                       tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\r\n",
        "#                                       tf.keras.layers.Dense(7, activation=tf.nn.softmax), # 7 classifications\r\n",
        "#                                     ])\r\n",
        "          \r\n",
        "#   vgghp_model.compile(optimizer=hparams[HP_OPTIMIZER],\r\n",
        "#                 loss='categorical_crossentropy',\r\n",
        "#                 metrics=['accuracy'],\r\n",
        "#   )\r\n",
        "  \r\n",
        "#   history = vgghp_model.fit(train_auto,epochs=50)\r\n",
        "#   validation_data=(valid_auto),  \r\n",
        " \r\n",
        "#   return history.history['accuracy'][-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkbuhWYQWFn5"
      },
      "source": [
        "#For each run, log an hparams summary with the hyperparameters and final accuracy:\r\n",
        "def run(run_dir, hparams):\r\n",
        "  with tf.summary.create_file_writer(run_dir).as_default():\r\n",
        "    hp.hparams(hparams)  # record the values used in this trial\r\n",
        "    accuracy = train_test_model(hparams)\r\n",
        "    accuracy= tf.reshape(tf.convert_to_tensor(accuracy), []).numpy()\r\n",
        "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w3GrqYDWGyx"
      },
      "source": [
        "#Start run & log them\r\n",
        "session_num = 0\r\n",
        "for fine_tune_at in HP_FREEZE.domain.values:\r\n",
        "  for num_units in HP_NUM_UNITS.domain.values:\r\n",
        "    for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\r\n",
        "      for optimizer in HP_OPTIMIZER.domain.values:\r\n",
        "        hparams = {\r\n",
        "          HP_FREEZE: fine_tune_at,\r\n",
        "          HP_NUM_UNITS: num_units,\r\n",
        "          HP_DROPOUT: dropout_rate,\r\n",
        "          HP_OPTIMIZER: optimizer,\r\n",
        "      }\r\n",
        "      run_name = \"run-%d\" % session_num\r\n",
        "      print('--- Starting trial: %s' % run_name)\r\n",
        "      print({h.name: hparams[h] for h in hparams})\r\n",
        "      run('logs/hparam_vgg/' + run_name, hparams)\r\n",
        "      session_num += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45o5Rs6_db6t"
      },
      "source": [
        "#Accessing Tensorboard hyperparameter plugin\r\n",
        "%tensorboard --logdir logs/hparam_vgg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azZweA-2hLct"
      },
      "source": [
        "# **Recalibrate VGG Hyperparameter**\r\n",
        "\r\n",
        "---\r\n",
        "Combination : Freeze layer (5), Dense layer(512), dropout (0.1),\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZPfVz8Fg9L1"
      },
      "source": [
        "#Experimenting with tuning the Pretrained Layer\r\n",
        "\r\n",
        "vgg_base = VGG16(include_top= False, weights='imagenet', input_shape = (48,48,3))\r\n",
        "\r\n",
        "#set freeze & unfreeze layer\r\n",
        "#vgg_base.trainable = False #freeze all so gradient descend wont modify them\r\n",
        "vgg_base.trainable = True #unfreeze specified layer to let backprop tweak them to increase performance (Rule: >train data >layer can unfreeze )\r\n",
        "\r\n",
        "print(\"Number of layers in the base model: \", len(vgg_base.layers))\r\n",
        "\r\n",
        "# Fine-tune from this layer onwards (make sure to unfreeze layer first before finetune)\r\n",
        "fine_tune_at = 5 # backprop will tweak layer 16 to 19\r\n",
        "\r\n",
        "# Freeze all the layers before the `fine_tune_at` layer\r\n",
        "for layer in vgg_base.layers[:fine_tune_at]:\r\n",
        "  layer.trainable =  False\r\n",
        "vgg_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKVT-j-FigRT"
      },
      "source": [
        "# Define model as Sequential class\r\n",
        "# model_vggbest = tf.keras.models.Sequential([tf.keras.applications.VGG16(include_top= False, weights='imagenet', input_shape = (48,48,3)),\r\n",
        "#                                       tf.keras.layers.Flatten(),\r\n",
        "#                                       tf.keras.layers.Dense(512, activation='tanh'),\r\n",
        "#                                       tf.keras.layers.Dropout(0.1),\r\n",
        "#                                       tf.keras.layers.Dense(7, activation=tf.nn.softmax), # 7 classifications\r\n",
        "#                                     ])\r\n",
        "          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hinofYwuzn8"
      },
      "source": [
        "model_vggbest = models.Sequential()\r\n",
        "model_vggbest.add(vgg_base)\r\n",
        "model_vggbest.add(BatchNormalization(momentum=0.5, trainable=True))\r\n",
        "model_vggbest.add(layers.GlobalAveragePooling2D())\r\n",
        "model_vggbest.add(layers.Dense(512, activation='tanh'))#Densee layer 512 best hyperparameter\r\n",
        "model_vggbest.add(BatchNormalization(momentum=0.5, trainable=True))\r\n",
        "model_vggbest.add(layers.Dropout (0.1)) #dropout 0.1 best hyperparameter\r\n",
        "model_vggbest.add(layers.Dense(128, activation='tanh'))\r\n",
        "model_vggbest.add(BatchNormalization(momentum=0.5, trainable=True))\r\n",
        "model_vggbest.add(layers.Dropout (0.1))\r\n",
        "model_vggbest.add(layers.Dense(16, activation='tanh'))\r\n",
        "model_vggbest.add(BatchNormalization(momentum=0.5, trainable=True))\r\n",
        "model_vggbest.add(layers.Dropout (0.1))\r\n",
        "model_vggbest.add(layers.Dense(7, activation='softmax')) # 7 classifications\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJXWPsCvqgx0"
      },
      "source": [
        "# # Define model as Sequential class using default transfer learning setting\r\n",
        "# model_vggbest = models.Sequential()\r\n",
        "# model_vggbest.add(vgg_base) # load the pre-trained base model (Load Process)\r\n",
        "# model_vggbest.add(layers.GlobalAveragePooling2D())\r\n",
        "# model_vggbest.add(layers.Dense(512, activation='relu'))\r\n",
        "# model_vggbest.add(layers.Dropout(0.1))\r\n",
        "# model_vggbest.add(layers.Dense(64, activation='relu'))\r\n",
        "# model_vggbest.add(layers.Dropout(0.1))\r\n",
        "# model_vggbest.add(layers.Dense(7, activation='softmax')) # 7 classifications\r\n",
        "# #model_vggip.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSqEjmoJhVmF"
      },
      "source": [
        "model_vggbest.compile(loss='categorical_crossentropy',\r\n",
        "                      optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.5), #0.01 is the best learning rate based on hyperparameter tuning,\r\n",
        "                      metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V2WTS-XuV9J"
      },
      "source": [
        "#to stop overfitting\r\n",
        "earlystop = EarlyStopping(monitor='val_loss',\r\n",
        "                              min_delta=0.01, #minimum change for improvement\r\n",
        "                              patience=10, # trigger when there is no improvement\r\n",
        "                              verbose=0, mode='auto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rOqTE7chfXQ"
      },
      "source": [
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logdir/vggbest/\", histogram_freq=1, profile_batch='15,20')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tgly7f5hjse"
      },
      "source": [
        "history_vgg = model_vggbest.fit(train_auto,\r\n",
        "                    epochs=50,\r\n",
        "                    #batch_size=10,\r\n",
        "                    validation_data=(valid_auto), \r\n",
        "                    callbacks = [tensorboard_callback, earlystop])\r\n",
        "\r\n",
        "#save all model\r\n",
        "model_vggbest.save('/content/drive/MyDrive/Fuad_Assignment/vgg_model(All).h5')# save in hdfs format\r\n",
        "tf.keras.models.save_model(model_vggbest,'/content/drive/MyDrive/Fuad_Assignment/vgg_tfmodel(All)')# save in Tensorflow format  \r\n",
        "#save weight only\r\n",
        "model_vggbest.save_weights('/content/drive/MyDrive/Fuad_Assignment/vgg_model(weight)v1.h5')  \r\n",
        "#save architecture only\r\n",
        "json_string=model_vggbest.to_json() \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lsNqt1KnDZY"
      },
      "source": [
        "#evaluate the model using test set\r\n",
        "model_vggbest.evaluate(x_test_rgb,y_test)\r\n",
        "model_vggbest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgeQ2R8GyiBK"
      },
      "source": [
        "%tensorboard --logdir /content/logdir/vggbest/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDw3WUrj7VoD"
      },
      "source": [
        "# **RESNET50 Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3zPJ0CxWgvo"
      },
      "source": [
        "Preprocess for Resnet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coDXiUGgQmom"
      },
      "source": [
        "#Clear Previous memory allocation\r\n",
        "%reset -f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGk2jdVgWeso"
      },
      "source": [
        "# Reshape 1D array to 2D matrix for Conv2D\r\n",
        "\r\n",
        "x_train = []\r\n",
        "for i in range(len(train_df)):\r\n",
        "  # convert string of pixels to list of integers and standarize data\r\n",
        "  list_pixels = [int(string)/255 for string in train_df.iloc[i,1].split(' ')]\r\n",
        "  # reshape 1D to 2D matrix\r\n",
        "  pixeled_image = np.array(list_pixels).reshape(48,48)\r\n",
        "  x_train.append(pixeled_image)\r\n",
        "\r\n",
        "x = np.array(x_train)\r\n",
        "y = train_df.iloc[:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbgA2NItWoLK"
      },
      "source": [
        "# Categorize y to y category for compatiblity with softmax activation\r\n",
        "from keras.utils import to_categorical\r\n",
        "y = to_categorical(np.array(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMzGFC2LWn5B"
      },
      "source": [
        "# print(x.shape) # (4178, 48, 48)\r\n",
        "# y.shape # (4178, 7)\r\n",
        "# (4178, 48, 48)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XPTKUxkWnDy"
      },
      "source": [
        "# Train_test_split training data into training and test sets\r\n",
        "x_train_r, x_test_r, y_train_r, y_test_r =  train_test_split(x, y, \\\r\n",
        "                                          random_state = 123, test_size = 0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt85aVfXWm0i"
      },
      "source": [
        "# Create train_test_split for validation sets\r\n",
        "x_trainRN, x_valRN, y_trainRN, y_valRN = train_test_split(x_train_r, y_train_r, random_state = 123, test_size = 0.30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nYffv9zWmnI"
      },
      "source": [
        "# Check shapes to ensure it's right\r\n",
        "print(x_trainRN.shape) # (17081, 48, 48)\r\n",
        "print(x_test_r.shape) # (4307, 48, 48)\r\n",
        "print(y_trainRN.shape) # (17081, 7)\r\n",
        "print(y_test_r.shape) # (4307, 7)\r\n",
        "print(x_valRN.shape) # (7321, 48,48)\r\n",
        "print(y_valRN.shape) #(7321,7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzrgaxUHW3EP"
      },
      "source": [
        "# Reshape the data to be  (2924, 48, 48, 1) and (1254, 48, 48, 1) for x_train and x_val\r\n",
        "# respectively. need to do this because input_shape in model_cnn.add needs a 2D image with \r\n",
        "# depth specified as 1\r\n",
        "x_train_reshaped5 = np.expand_dims(x_trainRN, axis = 3)\r\n",
        "x_val_reshaped5 = np.expand_dims(x_valRN, axis = 3)\r\n",
        "x_test_reshaped5 = np.expand_dims(x_test_r, axis = 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R4Fw_dFW2xH"
      },
      "source": [
        "# Need to repeat our 48x48x1 from 1 channel to 3 channel, because transfer learning models take RGB format\r\n",
        "#For Resnet Model\r\n",
        "x_train_rgb50 = np.repeat(x_train_reshaped5, 3, axis=3)\r\n",
        "x_val_rgb50 = np.repeat(x_val_reshaped5, 3, axis=3)\r\n",
        "x_test_rgb50 = np.repeat(x_test_reshaped5, 3, axis=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNjjK2PKXISS"
      },
      "source": [
        "print(x_train_rgb50.shape) #(3008, 48, 48, 3)\r\n",
        "print(x_val_rgb50.shape) #(752, 48, 48, 3)\r\n",
        "print(x_test_rgb50.shape) #(418, 48, 48, 3)\r\n",
        "print(x_train_rgb50.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04VEENSlXIC0"
      },
      "source": [
        "#Note:- For Training Model (x_train_rgb50, y_trainRN) Validation (x_val_rgb50, y_valRN) Testing (x_test_rgb50, y_test_r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ONlGgMpXViR"
      },
      "source": [
        "#set batch for dataset\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY3jbetiFcWD"
      },
      "source": [
        "Freeze & Unfreeze Layer for Resnet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuGB3Z9z7PZt"
      },
      "source": [
        "#Experimenting with tuning the Pretrained Layer\r\n",
        "\r\n",
        "resnet_base = ResNet50(include_top= False, weights='imagenet', input_shape = (48,48,3))\r\n",
        "\r\n",
        "#set freeze & unfreeze layer\r\n",
        "#resnet_base.trainable = False #freeze all so gradient descend wont modify them\r\n",
        "#resnet_base.trainable = True #unfreeze specified layer to let backprop tweak them to increase performance (Rule: >train data >layer can unfreeze )\r\n",
        "\r\n",
        "print(\"Number of layers in the base model: \", len(resnet_base.layers))\r\n",
        "\r\n",
        "# Fine-tune from this layer onwards (make sure to unfreeze layer first before finetune)\r\n",
        "#fine_tune_at = 20 # backprop will tweak layer 100 to 175\r\n",
        "\r\n",
        "# Freeze all the layers before the `fine_tune_at` layer\r\n",
        "#for layer in resnet_base.layers[fine_tune_at:]:\r\n",
        "#  layer.trainable =  False\r\n",
        "#resnet_base.summary()\r\n",
        "\r\n",
        "#for layer in resnet_base.layers:\r\n",
        "#   if isinstance(layer, keras.layers.BatchNormalization):\r\n",
        "#     layer.trainable = True\r\n",
        "#   else:\r\n",
        "#     layer.trainable = False\r\n",
        "#resnet_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KuFfvAEC6sA"
      },
      "source": [
        "resnet_base.trainable = True #False = Freeze all | True = Train Selected Layer\r\n",
        "\r\n",
        "#Fine-tune from this layer onwards (make sure to unfreeze layer first before finetune)\r\n",
        "fine_tune_at = 172 # backprop will tweak layer 20 to 175\r\n",
        "\r\n",
        "# Freeze all the layers before the `fine_tune_at` layer\r\n",
        "for layer in resnet_base.layers[:fine_tune_at]:\r\n",
        "   layer.trainable =  False\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzNFTCQZg6B7"
      },
      "source": [
        "**Due to small dataset, Data Augmentation is required in order for the model generalize better**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml8b6d92guCq"
      },
      "source": [
        "#data augmentation\r\n",
        "data_augmentation = keras.Sequential(\r\n",
        "    [\r\n",
        "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\r\n",
        "        layers.experimental.preprocessing.RandomRotation(0.1),\r\n",
        "    ]\r\n",
        ")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyDJlgMRCh5k"
      },
      "source": [
        "# #Experiment with top layer #1\r\n",
        "# x = resnet_base.output\r\n",
        "# x = data_augmentation(x)\r\n",
        "# x = keras.layers.GlobalAveragePooling2D()(x)\r\n",
        "# x = keras.layers.Dense(128,activation='tanh')(x)\r\n",
        "# x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\r\n",
        "# x = keras.layers.Dense(64, activation='tanh')(x)\r\n",
        "# # A Dense classifier with a multiple unit (multiple classification)\r\n",
        "# outputs = keras.layers.Dense(7, activation='softmax')(x)\r\n",
        "# model = keras.Model(resnet_base.input, outputs)\r\n",
        "# plot_model(model)\r\n",
        "# Epoch 100/100\r\n",
        "# #32/32 [==============================] - 5s 170ms/step - loss: 1.7273 - acc: 0.2987 - val_loss: 1.7301 - val_acc: 0.3051"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofn25RNahebL"
      },
      "source": [
        "#experiment with top layer #2 #best Top Layer\r\n",
        "x = resnet_base.output\r\n",
        "#x = data_augmentation(x)\r\n",
        "#x = keras.layers.BatchNormalization()(x)\r\n",
        "x = keras.layers.BatchNormalization(momentum=0.5, trainable=True)(x)\r\n",
        "#x = keras.layers.Activation('relu')(x)\r\n",
        "#x = keras.layers.GlAveragePooling2D(pool_size=2)(x)\r\n",
        "y = keras.layers.GlobalAveragePooling2D()(x)\r\n",
        "#y = keras.layers.Flatten()(x)\r\n",
        "#y = keras.layers.Dense(512, activation='relu')(y)\r\n",
        "y = keras.layers.Dense(512, activation='relu')(y)\r\n",
        "y = keras.layers.BatchNormalization(momentum=0.5, trainable=True)(y)\r\n",
        "y = keras.layers.Dropout(0.1)(y)\r\n",
        "y = keras.layers.Dense(128, activation='relu')(y)\r\n",
        "y = keras.layers.BatchNormalization(momentum=0.5, trainable=True)(y)\r\n",
        "y = keras.layers.Dropout(0.1)(y)\r\n",
        "y = keras.layers.Dense(32, activation='relu')(y)\r\n",
        "y = keras.layers.BatchNormalization(momentum=0.5, trainable=True)(y)\r\n",
        "y = keras.layers.Dropout(0.1)(y)\r\n",
        "# y = keras.layers.BatchNormalization()(y)\r\n",
        "# y = keras.layers.Dropout(0.5)(y)\r\n",
        "outputs = keras.layers.Dense(7, activation='softmax')(y)\r\n",
        "\r\n",
        "#instantiate model\r\n",
        "model = keras.Model(resnet_base.input, outputs)\r\n",
        "plot_model(model)\r\n",
        "\r\n",
        "# #Epoch 100/100\r\n",
        "# #33/33 [==============================] - 6s 180ms/step - loss: 1.4303 - acc: 0.4418 - val_loss: 1.6767 - val_acc: 0.3475"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqpn9oZO7fpT"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\r\n",
        "                  optimizer=keras.optimizers.SGD(0.01),\r\n",
        "                  metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEBjiT-SA7Qh"
      },
      "source": [
        "#to stop overfitting\r\n",
        "earlystop = EarlyStopping(monitor='val_loss',\r\n",
        "                              min_delta=0.01, #minimum change for improvement\r\n",
        "                              patience=10, # trigger when there is no improvement\r\n",
        "                              verbose=0, mode='auto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO3inA2-712z"
      },
      "source": [
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logdir/resnet/\", histogram_freq=1, profile_batch='15,20')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "492gTnbN8HzC"
      },
      "source": [
        "history_res = model.fit(x_train_rgb50,\r\n",
        "                    y_trainRN,\r\n",
        "                    epochs=500,\r\n",
        "                    batch_size=647, #total train = 20670/647 = 32 each step \r\n",
        "                    validation_data=(x_val_rgb50, y_valRN), \r\n",
        "                    callbacks = [tensorboard_callback, earlystop])\r\n",
        "\r\n",
        "#Experiment 1 (Freeze all layer)\r\n",
        "#Epoch 15/15\r\n",
        "#301/301 [==============================] - 7s 25ms/step - loss: 1.7564 - acc: 0.3341 - val_loss: 1.6664 - val_acc: 0.3830\r\n",
        "#experiment 2 (unfreeze at layer 160)\r\n",
        "#Epoch 100/100\r\n",
        "#\r\n",
        "#experiment 3 (unfreeze at layer 20)\r\n",
        "#Epoch 100/100\r\n",
        "#301/301 [==============================] - 10s 34ms/step - loss: 0.7092 - acc: 0.7763 - val_loss: 0.8134 - val_acc: 0.7420\r\n",
        "#Summary of experiment\r\n",
        "#Perform much better if unfreeze the layer for backprop to tweak the weight\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36N5kOJxZ7EI"
      },
      "source": [
        "#evaluate the model using test set\r\n",
        "model.evaluate(x_test_rgb50,y_test_r)\r\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDDzmLgI8SAu"
      },
      "source": [
        "%tensorboard --logdir /content/logdir/resnet/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmRmVniGhWst"
      },
      "source": [
        "# **Input PipeLine Experiment (ResNet50)**\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "As in real life deep learning problem will handle more larger set that will not fit in the memory, we will emulate of building data pipeline that extract data from distributed system. For this we use tensorflow input pipeline. we will used ETL principle:\r\n",
        "* Extract (extract the data from in memory to data pipeline)\r\n",
        "* Transform (normalize, transform the data)\r\n",
        "* Load (load to training model)\r\n",
        "\r\n",
        "**Transformation** \\\\\r\n",
        "Below are the transformation technique in this experiment to transform data using tf input pipeline \r\n",
        "* Shuffle - Prevent data from remembering pattern from training data that will make the model unable to generalize well\r\n",
        "* Batch - for very large dataset, processing small chunk of data at time will make \r\n",
        "* Prefetch - prefetching increace efficentcy of accelerator (GPU/TPU) by preventing pipeline waiting for preprocessing by CPU to finish. its prefetch the data ahead of time to GPU to avoid valuable cycle doing nothing.\r\n",
        "* Interleave - Interleave is similar to shuffle function except its shuffle the instance to avoid data learning from ordering of the data. Then there is AUTOTUNE which we let tensorflow to automatically choose the value dynamically at runtime.\r\n",
        "\r\n",
        "**Load** \\\\\r\n",
        "Finally after the transformation stage complete, we feed the data into the model\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb9zsTSAlACe"
      },
      "source": [
        "#change the dataset type from float64 to float32 (lower the bit faster the process but effect accuracy)\r\n",
        "x_train_rgb50 = tf.cast(x_train_rgb50, tf.float32)\r\n",
        "x_val_rgb50 = tf.cast (x_val_rgb50, tf.float32)\r\n",
        "x_test_rgb50 = tf.cast (x_test_rgb50, tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHH6-rtrlnSL"
      },
      "source": [
        "#extract dataset into Tensorflow tf.data (API for input pipeline)\r\n",
        "train_ip1 = tf.data.Dataset.from_tensor_slices((x_train_rgb50, y_trainRN)).batch(256)\r\n",
        "valid_ip1 =tf.data.Dataset.from_tensor_slices((x_val_rgb50, y_valRN)).batch(256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cnmoqVYmbWs"
      },
      "source": [
        "# START THE TRANSFORMING PROCESS\r\n",
        "#function to normalize image \r\n",
        "def normalize_img (image, label):\r\n",
        "  return tf.cast(image, tf.float32)/255.0, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEpVT7neml4G"
      },
      "source": [
        "#Automatic the tuning parameter in data pipeline\r\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbrOqPIhmv1G"
      },
      "source": [
        "train_auto1 = train_ip1.map(normalize_img,num_parallel_calls=AUTOTUNE)# Normalization the data function using map function \r\n",
        "train_auto1 = train_ip1.cache() #caches the dataset after normalizing the images\r\n",
        "train_auto1 = train_ip1.shuffle(buffer_size= 100) # to create randomness in dataset so to avoid bias when training the model\r\n",
        "train_auto1 = train_ip1.batch(batch_size=512)# number of image batch into data pipeline\r\n",
        "train_auto1 = train_ip1.prefetch(buffer_size = AUTOTUNE) #to alter the preprocessing execution\r\n",
        "valid_auto1 = valid_ip1.map(normalize_img,num_parallel_calls=AUTOTUNE)\r\n",
        "valid_auto1 = valid_ip1.batch(batch_size=128)\r\n",
        "valid_auto1 = valid_ip1.prefetch(buffer_size= AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjTMscFUb6P2"
      },
      "source": [
        "## **Feed the tensor to model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPlk5yjOhd0y"
      },
      "source": [
        "resnet_ip = ResNet50(include_top= False, weights='imagenet', input_shape = (48,48,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTM7ClzEle7_"
      },
      "source": [
        "resnet_ip.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIN5snh_zoy_"
      },
      "source": [
        "data_augmentation = keras.Sequential(\r\n",
        "    [\r\n",
        "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\r\n",
        "        layers.experimental.preprocessing.RandomRotation(0.1),\r\n",
        "    ]\r\n",
        ")\r\n",
        "\r\n",
        "x= resnet_base.output\r\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\r\n",
        "x = keras.layers.Dense(128,activation='tanh')(x)\r\n",
        "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\r\n",
        "x = keras.layers.Dense(64, activation='tanh')(x)\r\n",
        "# A Dense classifier with a single unit (binary classification)\r\n",
        "outputs = keras.layers.Dense(7, activation='softmax')(x)\r\n",
        "model_ip1 = keras.Model(resnet_base.inputs, outputs)\r\n",
        "model_ip1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhMuNDWMnfn1"
      },
      "source": [
        "model_ip1.compile(loss='categorical_crossentropy',\r\n",
        "                  optimizer=keras.optimizers.SGD(1e-5),\r\n",
        "                  metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQc7QFgKiuKr"
      },
      "source": [
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logdir/resnet_IP/\", histogram_freq=1, profile_batch='15,20')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfFpTjlni7Bg"
      },
      "source": [
        "history_cnn = model_ip1.fit(train_auto1,\r\n",
        "                    epochs=15,\r\n",
        "                    validation_data=valid_auto1,\r\n",
        "                    callbacks = [tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lde0DyBzjH_D"
      },
      "source": [
        "%tensorboard --logdir /content/logdir/resnet_IP/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i36U-Gc3jOoX"
      },
      "source": [
        "# **HyperParameter GridSearch ResNet50**\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Tuned inspired by https://medium.com/ml-book/neural-networks-hyperparameter-tuning-in-tensorflow-2-0-a7b4e2b574a1\r\n",
        "\r\n",
        "From previous experiment, we find out that our model very slow to converge. This raise the question of\r\n",
        "* Which learning rate is the fast to converge?\r\n",
        "* Which layer to unfreeze to give best result ?\r\n",
        "* How many unit our dense layer need to perform?\r\n",
        "* What dropout rate is the best to avoid overfitting? \r\n",
        "\r\n",
        "Instead of guessing which parameter work best. we use grid search to find best combination\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "From running grid search we found that \r\n",
        "* learning rate 0.01 is better than 0.1\r\n",
        "* unfreeze middle layer give more accuracy than bottom or top (88 better than  120 and 30\r\n",
        "* 512 dense unit is the best\r\n",
        "* Drop rate 0.2 is better than 0.3\r\n",
        "the best accuracy of this combination for 15 epoch is 0.43145\r\n",
        "\r\n",
        "From the result of 1st run, refinement will be made on the hyperparameter. we will test as follow:-\r\n",
        "* will learning rate 0.001 better than current best (0.01)?\r\n",
        "* will unfreeze layer 73 and 103 (+-15 from current best 88) give better result\r\n",
        "* we are satisfied with 512 dense unit so no more refinement\r\n",
        "* Will drop rate 01 is better than current best (0.2) \r\n",
        "\r\n",
        "Best combination (Unfreeze at 88 layer, Dense Unit (88), Dropout (10) LR(0.01)\r\n",
        "Accuracy after 15 epoch = 0.465"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yErTVvvUFIX8"
      },
      "source": [
        "# #Hyperparameter 1st Run\r\n",
        "# HP_FREEZE = hp.HParam('fine_tune_at', hp.Discrete([58, 88, 120])) \r\n",
        "# HP_NUM_UNITS2 = hp.HParam('num_units2', hp.Discrete([256,512]))\r\n",
        "# HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.2,0.3))\r\n",
        "# HP_LR = hp.HParam('learning_rate', hp.RealInterval(0.01, 0.1))\r\n",
        "\r\n",
        "# METRIC_ACCURACY = 'accuracy'\r\n",
        "\r\n",
        "# with tf.summary.create_file_writer('logs/hparam_tuningResNet50').as_default():\r\n",
        "#   hp.hparams_config(\r\n",
        "#     hparams=[HP_FREEZE,HP_NUM_UNITS2, HP_DROPOUT, HP_LR],\r\n",
        "#     metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\r\n",
        "#   )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCDDuLXTsD_H"
      },
      "source": [
        "#Hyperparamater 2nd Run\r\n",
        "\r\n",
        "HP_FREEZE = hp.HParam('fine_tune_at', hp.Discrete([73, 88, 103])) \r\n",
        "HP_NUM_UNITS2 = hp.HParam('num_units2', hp.Discrete([512]))\r\n",
        "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1,0.2))\r\n",
        "HP_LR = hp.HParam('learning_rate', hp.RealInterval(0.001, 0.01))\r\n",
        "\r\n",
        "METRIC_ACCURACY = 'accuracy'\r\n",
        "\r\n",
        "with tf.summary.create_file_writer('logs/hparam_tuningResNet50_2nd').as_default():\r\n",
        "  hp.hparams_config(\r\n",
        "    hparams=[HP_FREEZE,HP_NUM_UNITS2, HP_DROPOUT, HP_LR],\r\n",
        "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\r\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwaOzfRYKEzt"
      },
      "source": [
        "#exp new dataset\r\n",
        "def train_test_resnetmodel(hparams):\r\n",
        "    resnet_base = ResNet50(include_top= False, weights='imagenet', input_shape = (48,48,3))\r\n",
        "    resnet_base.trainable = False #False = Freeze all | True = Train Selected Layer\r\n",
        "\r\n",
        "    #Fine-tune from this layer onwards (make sure to unfreeze layer first before finetune)\r\n",
        "    fine_tune_at = hparams[HP_FREEZE] # backprop will tweak layer 20 to 175\r\n",
        "\r\n",
        "# Freeze all the layers before the `fine_tune_at` layer\r\n",
        "    for layer in resnet_base.layers[:fine_tune_at]:\r\n",
        "\r\n",
        "        layer.trainable =  False\r\n",
        "\r\n",
        "    data_augmentation = keras.Sequential(\r\n",
        "        [\r\n",
        "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\r\n",
        "        layers.experimental.preprocessing.RandomRotation(0.1),\r\n",
        "        ]\r\n",
        "    )\r\n",
        "\r\n",
        "     \r\n",
        "    x = resnet_base.output\r\n",
        "    x = data_augmentation(x)\r\n",
        "    x = keras.layers.BatchNormalization()(x)\r\n",
        "    x = keras.layers.Activation('relu')(x)\r\n",
        "    x = keras.layers.AveragePooling2D(pool_size=2)(x)\r\n",
        "    y = keras.layers.Flatten()(x)\r\n",
        "    y = keras.layers.Dense(hparams[HP_NUM_UNITS2], activation='relu')(y)\r\n",
        "    y = keras.layers.BatchNormalization()(y)\r\n",
        "    y = keras.layers.Dropout(hparams[HP_DROPOUT])(y)\r\n",
        "    outputs = keras.layers.Dense(7, activation='softmax')(y)\r\n",
        "\r\n",
        "    #instantiate model\r\n",
        "    res50_hp = keras.Model(resnet_base.input, outputs)\r\n",
        "          \r\n",
        "    res50_hp.compile(optimizer=keras.optimizers.SGD(learning_rate=hparams[HP_LR]),#here\r\n",
        "                loss='categorical_crossentropy',\r\n",
        "                metrics=['accuracy'],\r\n",
        "    )\r\n",
        "  \r\n",
        "    history = res50_hp.fit(train_auto1,epochs=15)\r\n",
        "    validation_data=(valid_auto1),  \r\n",
        "    #val_accuracy = model.evaluate(x_val_reshaped, y_val),\r\n",
        "  \r\n",
        "\r\n",
        "    return history.history['accuracy'][-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdxCwvYrjaIA"
      },
      "source": [
        "# HP_NUM_UNITS1 = hp.HParam('num_units1', hp.Discrete([128, 256]))\r\n",
        "# HP_NUM_UNITS2 = hp.HParam('num_units2', hp.Discrete([32,64]))\r\n",
        "# HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.2,0.3))\r\n",
        "# HP_LR = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd',]))\r\n",
        "\r\n",
        "# METRIC_ACCURACY = 'accuracy'\r\n",
        "\r\n",
        "# with tf.summary.create_file_writer('logs/hparam_tuningResNet50').as_default():\r\n",
        "#   hp.hparams_config(\r\n",
        "#     hparams=[HP_NUM_UNITS1,HP_NUM_UNITS2, HP_DROPOUT, HP_OPTIMIZER],\r\n",
        "#     metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\r\n",
        "#   )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZJdrFfSoVa3"
      },
      "source": [
        "# def train_test_resnetmodel(hparams):\r\n",
        "#     data_augmentation = keras.Sequential(\r\n",
        "#     [\r\n",
        "#         layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\r\n",
        "#         layers.experimental.preprocessing.RandomRotation(0.1),\r\n",
        "#     ]\r\n",
        "#     )\r\n",
        "\r\n",
        "     \r\n",
        "#     x = resnet_base.output\r\n",
        "#     x = keras.layers.GlobalAveragePooling2D()(x)\r\n",
        "#     x = keras.layers.Dense(hparams[HP_NUM_UNITS1],activation='tanh')(x)\r\n",
        "#     x = keras.layers.Dropout(hparams[HP_DROPOUT])(x)# Regularize with dropout\r\n",
        "#     x = keras.layers.Dense(hparams[HP_NUM_UNITS2], activation='tanh')(x)      \r\n",
        "#     # A Dense classifier with a single unit (binary classification)\r\n",
        "#     outputs = keras.layers.Dense(7, activation='softmax')(x)\r\n",
        "#     res50_hp = keras.Model(resnet_base.input, outputs)\r\n",
        "          \r\n",
        "#     res50_hp.compile(optimizer=hparams[HP_OPTIMIZER],#here\r\n",
        "#                 loss='categorical_crossentropy',\r\n",
        "#                 metrics=['accuracy'],\r\n",
        "#     )\r\n",
        "  \r\n",
        "#     history = res50_hp.fit(train_auto1,epochs=15)\r\n",
        "#     validation_data=(valid_auto1),  \r\n",
        "#     #val_accuracy = model.evaluate(x_val_reshaped, y_val),\r\n",
        "  \r\n",
        "\r\n",
        "#     return history.history['accuracy'][-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3NmZ6Blj8QU"
      },
      "source": [
        "def run(run_dir, hparams):\r\n",
        "  with tf.summary.create_file_writer(run_dir).as_default():\r\n",
        "    hp.hparams(hparams)  # record the values used in this trial\r\n",
        "    accuracy = train_test_resnetmodel(hparams)\r\n",
        "    accuracy= tf.reshape(tf.convert_to_tensor(accuracy), []).numpy()\r\n",
        "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqYZvhacMAON"
      },
      "source": [
        "session_num = 0\r\n",
        "\r\n",
        "for fine_tune_at in HP_FREEZE.domain.values:\r\n",
        "  for num_units2 in HP_NUM_UNITS2.domain.values:\r\n",
        "    for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\r\n",
        "      for learning_rate in (HP_LR.domain.min_value, HP_LR.domain.max_value):\r\n",
        "        hparams = {\r\n",
        "            HP_FREEZE: fine_tune_at,\r\n",
        "            HP_NUM_UNITS2: num_units2,\r\n",
        "            HP_DROPOUT: dropout_rate,\r\n",
        "            HP_LR: learning_rate,\r\n",
        "        }\r\n",
        "        run_name = \"run-%d\" % session_num\r\n",
        "        print('--- Starting trial: %s' % run_name)\r\n",
        "        print({h.name: hparams[h] for h in hparams})\r\n",
        "        run('logs/hparam_tuningResNet50_2nd/' + run_name, hparams)\r\n",
        "        session_num += 1\r\n",
        "\r\n",
        "#result\r\n",
        "#512 unit is the best\r\n",
        "#lower dropout good result (0.2 is better than 0.3)\r\n",
        "#learning rate lower the better (0.01 is better than 0.1)\r\n",
        "#unfreeze upper level more accurate (120 is better than 88 than 58)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VEwCchvkBMN"
      },
      "source": [
        "# session_num = 0\r\n",
        "\r\n",
        "# for num_units1 in HP_NUM_UNITS1.domain.values:\r\n",
        "#   for num_units2 in HP_NUM_UNITS2.domain.values:\r\n",
        "#     for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\r\n",
        "#       for optimizer in HP_OPTIMIZER.domain.values:\r\n",
        "#         hparams = {\r\n",
        "#             HP_NUM_UNITS1: num_units1,\r\n",
        "#             HP_NUM_UNITS2: num_units2,\r\n",
        "#             HP_DROPOUT: dropout_rate,\r\n",
        "#             HP_OPTIMIZER: optimizer,\r\n",
        "#         }\r\n",
        "#         run_name = \"run-%d\" % session_num\r\n",
        "#         print('--- Starting trial: %s' % run_name)\r\n",
        "#         print({h.name: hparams[h] for h in hparams})\r\n",
        "#         run('logs/hparam_tuningResNet50/' + run_name, hparams)\r\n",
        "#         session_num += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G5lAK8Cklux"
      },
      "source": [
        "#Accessing hyperparameter plugin\r\n",
        "%tensorboard --logdir logs/hparam_tuningResNet50_2nd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO8FK7fc4Cbx"
      },
      "source": [
        "# **Recalibrate Resnet Model with Best Hyperparameter**\r\n",
        "using test dataset\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "Best Architecture: ResNet50\r\n",
        "HyperParameter: Fine tune at (88), Dense layer I(512), learning rate(0.01), Dropout (0.1)\r\n",
        "\r\n",
        "---\r\n",
        "Based on the best combination of hyperparameter, we retrain our model. we then monitor the performance of the model closely. once we spotted gradient explotion on the validation loss, we interrupt the kernel and tweak the top layer by adding more dense layer. If the validation loss behave erraticly i.e. the loss increase exponentially then sudden decrease, we adjust the learning rate to be more slower than previous.\r\n",
        "\r\n",
        "the training epoch is set up to 500 epoch as we not unable to predict when the model will converge.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdgBb39nwvzS"
      },
      "source": [
        "#input_t = keras.Input(shape=(48,48,3))\r\n",
        "resnet_base = ResNet50(include_top= False, weights='imagenet', input_shape= (48,48,3))\r\n",
        "resnet_base.trainable = True\r\n",
        "\r\n",
        "#Fine-tune from this layer onwards (make sure to unfreeze layer first before finetune)\r\n",
        "fine_tune_at = 88 # backprop will tweak layer 88 to 175 based on best hyperparameter tuning\r\n",
        "# Freeze all the layers before the `fine_tune_at` layer\r\n",
        "for layer in resnet_base.layers[:fine_tune_at]:\r\n",
        "   layer.trainable =  False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWQktE2yq3kI"
      },
      "source": [
        "# x= resnet_base.output\r\n",
        "# x = keras.layers.GlobalAveragePooling2D()(x)\r\n",
        "# x = keras.layers.Dense(256,activation='tanh')(x)\r\n",
        "# x = keras.layers.Dropout(0.5)(x)  # Regularize with dropout\r\n",
        "# # x = keras.layers.Dense(128, activation='tanh')(x)\r\n",
        "# # x = keras.layers.Dropout(0.5)(x)  # Regularize with dropout\r\n",
        "# x = keras.layers.Dense(64, activation='tanh')(x)\r\n",
        "\r\n",
        "# # A Dense classifier with a single unit (binary classification)\r\n",
        "# outputs = keras.layers.Dense(7, activation='softmax')(x)\r\n",
        "# modelx = keras.Model(resnet_base.inputs, outputs)\r\n",
        "# modelx.summary()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-C0FeN-gDxF"
      },
      "source": [
        "# x= resnet_base.output\r\n",
        "# x = keras.layers.GlobalAveragePooling2D()(x)\r\n",
        "# #x = keras.layers.Dense(1024,activation='relu')(x)\r\n",
        "# #x= keras.layers.BatchNormalization()(x)\r\n",
        "# #x = keras.layers.Dropout(0.3)(x)  # Regularize with dropout\r\n",
        "# x = keras.layers.Dense(512, activation='relu')(x)\r\n",
        "# #x = keras.layers.BatchNormalization()(x)\r\n",
        "# x = keras.layers.Dropout(0.5)(x)\r\n",
        "# #x = keras.layers.Dense(512, activation='relu')(x)\r\n",
        "# #x = keras.layers.BatchNormalization()(x)\r\n",
        "# x = keras.layers.Dense(64, activation='relu')(x)\r\n",
        "# x = keras.layers.Dropout(0.5)(x)\r\n",
        "# # A Dense classifier with a single unit (binary classification)\r\n",
        "# outputs = keras.layers.Dense(7, activation='softmax')(x)\r\n",
        "# modelx = keras.Model(resnet_base.inputs, outputs)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuUcPzH_9HqN"
      },
      "source": [
        "data_augmentation = keras.Sequential(\r\n",
        "    [\r\n",
        "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\r\n",
        "        layers.experimental.preprocessing.RandomRotation(0.1),\r\n",
        "    ]\r\n",
        ")\r\n",
        "\r\n",
        "x = resnet_base.output\r\n",
        "x = data_augmentation(x)  \r\n",
        "x = keras.layers.BatchNormalization()(x)\r\n",
        "x = keras.layers.Activation('relu')(x)\r\n",
        "x = keras.layers.AveragePooling2D(pool_size=2)(x)\r\n",
        "y = keras.layers.Flatten()(x)\r\n",
        "y = keras.layers.Dense(512, activation='relu')(y)  #512 unit is the best based on hyperparameter tuning\r\n",
        "y = keras.layers.BatchNormalization()(y)\r\n",
        "y = keras.layers.Dense(512, activation='relu')(y)\r\n",
        "y = keras.layers.BatchNormalization()(y)\r\n",
        "y = keras.layers.Dropout(0.1)(y) #0.1 is the best based on hyperparameter tuning\r\n",
        "outputs = keras.layers.Dense(7, activation='softmax')(y)\r\n",
        "\r\n",
        "#instantiate model\r\n",
        "modelx = keras.Model(resnet_base.input, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcG3zCbSZVYa"
      },
      "source": [
        "#add Learning rate scheduler & momentum to speed up convergence\r\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\r\n",
        "    initial_learning_rate=1e-2,\r\n",
        "    decay_steps=10000,\r\n",
        "    decay_rate=0.9)\r\n",
        "\r\n",
        "modelx.compile(loss='categorical_crossentropy', \r\n",
        "                  optimizer=keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.1), #0.01 is the best learning rate based on hyperparameter tuning\r\n",
        "                  metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czTLiLx1XekI"
      },
      "source": [
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logdir/resnet_bestmodelv1/\", histogram_freq=1, profile_batch='150,160')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy1KayvcZVYa"
      },
      "source": [
        "history_res = modelx.fit(train_auto1,\r\n",
        "                    epochs=100, #Run large iteration, interrupt when gradient vector become tiny number as gradient descent already reach global minima\r\n",
        "                    validation_data=(valid_auto1),\r\n",
        "                    callbacks = [tensorboard_callback]) \r\n",
        "\r\n",
        "#save all model\r\n",
        "modelx.save('/content/drive/MyDrive/Fuad_Assignment/resnet_model(All)v1.h5')# save in hdfs format\r\n",
        "tf.keras.models.save_model(modelx,'/content/drive/MyDrive/Fuad_Assignment/resnet_tfmodel(All)v1')# save in Tensorflow format  \r\n",
        "#save weight only\r\n",
        "modelx.save_weights('/content/drive/MyDrive/Fuad_Assignment/resnet_model(weight)v1.h5')  \r\n",
        "#save architecture only\r\n",
        "json_string=modelx.to_json() \r\n",
        "\r\n",
        "# The model seem to face Curse of Dimensionality "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDt76iQLreO_"
      },
      "source": [
        "#evaluate the model using test set\r\n",
        "modelx.evaluate(x_test_rgb50,y_test_r)\r\n",
        "modelx\r\n",
        "#135/135 [==============================] - 3s 16ms/step - loss: 2.7775 - acc: 0.4829"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubwaV3yPX1Mo"
      },
      "source": [
        "\r\n",
        "%tensorboard --logdir /content/logdir/resnet_bestmodelv1/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y6pX_Lwcb7t"
      },
      "source": [
        "# **Testing the Model on Random Image**\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "Final part of the experiment is testing outside experiment environment for evaluating real time performance against some random image. this is to validate that our training models can performed well against unseen data that not come from the same sources. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej-VXwaBcimE"
      },
      "source": [
        "#Clear Previous memory allocation\r\n",
        "%reset -f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg2pBB4WiGlm"
      },
      "source": [
        "#Load train model\r\n",
        "from keras.models import load_model\r\n",
        "new_model = tf.keras.models.load_model('/content/drive/MyDrive/Fuad_Assignment/resnet_tfmodel(All)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR5JnVRajZle"
      },
      "source": [
        "#function for drawing bar chart for emotion preditions\r\n",
        "def emotion_analysis(emotions):\r\n",
        "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\r\n",
        "    y_pos = np.arange(len(objects))\r\n",
        "    \r\n",
        "    plt.bar(y_pos, emotions, align='center', alpha=0.5)\r\n",
        "    plt.xticks(y_pos, objects)\r\n",
        "    plt.ylabel('percentage')\r\n",
        "    plt.title('emotion')\r\n",
        "    \r\n",
        "    plt.show()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y34b699IV0TD"
      },
      "source": [
        "# **Testing Random Image #1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfi3XTkHjkxX"
      },
      "source": [
        "#load some random image\r\n",
        "from keras.preprocessing import image\r\n",
        "img = tf.keras.preprocessing.image.load_img('/content/drive/MyDrive/Fuad_Assignment/jackman.png', grayscale=False, target_size=(48, 48) )#change image from google drive\r\n",
        "#preprocess the random image\r\n",
        "\r\n",
        "x = image.img_to_array(img)\r\n",
        "x = np.expand_dims(x,axis=0)\r\n",
        "x /= 255.\r\n",
        "custom = new_model.predict(x)\r\n",
        "emotion_analysis(custom[0])\r\n",
        "\r\n",
        "#x = np.array(x, 'float32')\r\n",
        "#x = x.reshape([48, 48]);\r\n",
        "\r\n",
        "plt.gray()\r\n",
        "plt.imshow(img)\r\n",
        "plt.show()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5A77zi5Vng9"
      },
      "source": [
        "# **Testing Random Image #2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqDFZkcnZXe5"
      },
      "source": [
        "#load some random image\r\n",
        "from keras.preprocessing import image\r\n",
        "img = tf.keras.preprocessing.image.load_img('/content/drive/MyDrive/Fuad_Assignment/sadspidey.jpg', grayscale=False, target_size=(48, 48) )#change image from google drive\r\n",
        "#preprocess the random image\r\n",
        "\r\n",
        "x = image.img_to_array(img)\r\n",
        "x = np.expand_dims(x,axis=0)\r\n",
        "x /= 255.\r\n",
        "custom = %timeit new_model.predict(x)\r\n",
        "emotion_analysis(custom[0])\r\n",
        "\r\n",
        "#x = np.array(x, 'float32')\r\n",
        "#x = x.reshape([48, 48]);\r\n",
        "\r\n",
        "plt.gray()\r\n",
        "plt.imshow(img)\r\n",
        "plt.show()\r\n",
        "\r\n",
        "end= datetime.datetime.now()\r\n",
        "elapsed= end-start\r\n",
        "print ('Time: ', elapsed)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}